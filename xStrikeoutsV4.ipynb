{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages and load libraries\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "from pybaseball import statcast\n",
    "from pybaseball import playerid_lookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Scraping Statcast from 2025-04-08 to 2025-04-08...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new games found. model_df is already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Load existing model_df and team_k_stats\n",
    "model_df = pd.read_csv(r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\model_df.csv\")\n",
    "team_k_stats = pd.read_csv(r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\team_k_stats.csv\")\n",
    "\n",
    "# 2. Find latest date\n",
    "latest_date_str = model_df['game_date'].max()\n",
    "latest_date = pd.to_datetime(latest_date_str) + timedelta(days=1)\n",
    "today = datetime.today()\n",
    "\n",
    "# 3. Scrape missing Statcast data\n",
    "print(f\"Scraping Statcast from {latest_date.date()} to {today.date()}...\")\n",
    "new_data = statcast(start_dt=latest_date.strftime(\"%Y-%m-%d\"), end_dt=today.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# 4. Check if any new data\n",
    "if new_data.empty:\n",
    "    print(\"No new games found. model_df is already up to date.\")\n",
    "else:\n",
    "    print(f\"Found {len(new_data)} new rows. Processing...\")\n",
    "\n",
    "    # Assign batting_team manually\n",
    "    new_data['batting_team'] = new_data.apply(\n",
    "        lambda x: x['away_team'] if x['inning_topbot'] == 'Top' else x['home_team'], axis=1\n",
    "    )\n",
    "\n",
    "    # Determine if pitcher is home/away based on inning side\n",
    "    new_data['is_home_game'] = new_data['inning_topbot'].apply(lambda x: 1 if x == 'Top' else 0)\n",
    "\n",
    "    # Correct player_team based on is_home_game\n",
    "    new_data['player_team'] = new_data.apply(\n",
    "        lambda x: x['home_team'] if x['is_home_game'] == 1 else x['away_team'], axis=1\n",
    "    )\n",
    "\n",
    "    # 5. Filter only pitching events\n",
    "    pitching_data = new_data[~new_data['pitch_type'].isna()]\n",
    "\n",
    "    # 6. Build features\n",
    "    pitcher_game = pitching_data.groupby(\n",
    "        ['player_name', 'game_date', 'pitcher', 'home_team', 'away_team', 'player_team']\n",
    "    ).agg(\n",
    "        avg_velocity=('release_speed', 'mean'),\n",
    "        pct_LHB_faced=('stand', lambda x: (x == 'L').mean()),\n",
    "        p_throws=('p_throws', 'first'),\n",
    "        total_strikeouts=('events', lambda x: (x == 'strikeout').sum()),\n",
    "        is_home_game=('is_home_game', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Static placeholders\n",
    "    pitcher_game['pitcher_days_since_prev_game'] = 5\n",
    "    pitcher_game['pitcher_days_until_next_game'] = 5\n",
    "    pitcher_game['ks_last_5_games'] = 5  # placeholder until recalculation\n",
    "    pitcher_game['k_pct_last_5_games'] = 0.22\n",
    "\n",
    "    # Add opponent_team\n",
    "    pitcher_game['opponent_team'] = pitcher_game.apply(\n",
    "        lambda x: x['away_team'] if x['is_home_game'] == 1 else x['home_team'], axis=1\n",
    "    )\n",
    "\n",
    "    # Placeholder for k_pct_60d\n",
    "    pitcher_game['k_pct_60d'] = 0.22\n",
    "\n",
    "    # 7. Reorder columns to match model_df\n",
    "    columns_to_keep = [\n",
    "        'player_name', 'game_date', 'avg_velocity', 'pct_LHB_faced', 'p_throws',\n",
    "        'pitcher_days_since_prev_game', 'pitcher_days_until_next_game',\n",
    "        'home_team', 'away_team', 'player_team', 'total_strikeouts', 'is_home_game',\n",
    "        'ks_last_5_games', 'k_pct_last_5_games', 'opponent_team', 'k_pct_60d'\n",
    "    ]\n",
    "    pitcher_game = pitcher_game[columns_to_keep]\n",
    "\n",
    "    # 8. Append new games to model_df\n",
    "    model_df['game_date'] = pd.to_datetime(model_df['game_date'])\n",
    "    model_df = pd.concat([model_df, pitcher_game], ignore_index=True)\n",
    "\n",
    "    # 9. Recalculate ks_last_5_games\n",
    "    model_df = model_df.sort_values(['player_name', 'game_date'])\n",
    "    model_df['ks_last_5_games'] = (\n",
    "        model_df.groupby('player_name')['total_strikeouts']\n",
    "        .rolling(window=5, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # 10. Rebuild team_k_stats \n",
    "    print(\"Rebuilding team K% stats...\")\n",
    "\n",
    "    # Only plate appearances (where events exist) and .copy()\n",
    "    pa_data = pitching_data[pitching_data['events'].notna()].copy()\n",
    "\n",
    "    # Only 2025 season games\n",
    "    pa_data['game_year'] = pd.to_datetime(pa_data['game_date']).dt.year\n",
    "    pa_data = pa_data[pa_data['game_year'] == 2025]\n",
    "\n",
    "    # Correct team K% calculation\n",
    "    team_k_stats = pa_data.groupby(['batting_team', 'p_throws']).agg(\n",
    "        total_pas=('batter', 'count'),\n",
    "        total_strikeouts=('events', lambda x: (x == 'strikeout').sum())\n",
    "    ).reset_index()\n",
    "\n",
    "    team_k_stats['k_pct_60d'] = team_k_stats['total_strikeouts'] / team_k_stats['total_pas']\n",
    "\n",
    "    # 11. Save updated files\n",
    "    model_df.to_csv(r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\model_df.csv\", index=False)\n",
    "    team_k_stats.to_csv(r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\team_k_stats.csv\", index=False)\n",
    "\n",
    "    print(\"Updated model_df and team_k_stats saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found:\n",
      "{'subsample': 0.7, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.03, 'gamma': 0.2, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# testing best parameters for the model, will implement below\n",
    "# THIS CHUNK HAS ALREADY BEEN RUN - PRINT STATEMENT WILL SHOW THE BEST PARAMETERS FOR XGBOOST\n",
    "\n",
    "\n",
    "# today = date.today()\n",
    "# dynamic_seed = int(today.strftime(\"%Y%m%d\"))\n",
    "\n",
    "# # 1. Define model\n",
    "# xgb = XGBRegressor(random_state=dynamic_seed)\n",
    "\n",
    "# # 2. Define search space\n",
    "# param_dist = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "#     'max_depth': [3, 4, 5, 6, 7],\n",
    "#     'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "#     'min_child_weight': [1, 3, 5],\n",
    "#     'gamma': [0, 0.1, 0.2]\n",
    "# }\n",
    "\n",
    "# # 3. Setup RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=30,             # Try 30 random combos\n",
    "#     scoring='neg_mean_squared_error',  # How to judge \"better\"\n",
    "#     cv=3,                  # 3-fold cross validation\n",
    "#     verbose=1,\n",
    "#     random_state=dynamic_seed,\n",
    "#     n_jobs=-1              # Use all cores\n",
    "# )\n",
    "\n",
    "# final_features = [\n",
    "#     'avg_velocity',\n",
    "#     'pct_LHB_faced',\n",
    "#     'pitcher_days_since_prev_game',\n",
    "#     'pitcher_days_until_next_game',\n",
    "#     'ks_last_5_games',\n",
    "#     'k_pct_60d',\n",
    "#     'is_home_game'  # Added\n",
    "# ]\n",
    "\n",
    "# X = model_df[final_features]\n",
    "# y = model_df['total_strikeouts']\n",
    "\n",
    "# model_df = model_df.sort_values('game_date').reset_index(drop=True)\n",
    "# model_df['recency_rank'] = model_df.index\n",
    "# model_df['recency_score'] = model_df['recency_rank'] / model_df['recency_rank'].max()\n",
    "# model_df['sample_weight'] = model_df['recency_score'] ** 2\n",
    "\n",
    "# sample_weight = model_df['sample_weight']\n",
    "\n",
    "# # 4. Fit\n",
    "# random_search.fit(X, y, sample_weight=sample_weight)\n",
    "\n",
    "# # 5. Best model\n",
    "# best_xgb = random_search.best_estimator_\n",
    "\n",
    "# print(\"Best Parameters Found:\")\n",
    "# print(random_search.best_params_)\n",
    "\n",
    "best_params = {\n",
    "    'subsample': 0.7,\n",
    "    'n_estimators': 300,\n",
    "    'min_child_weight': 1,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.03,\n",
    "    'gamma': 0.2,\n",
    "    'colsample_bytree': 1.0\n",
    "}\n",
    "\n",
    "print(\"Best Parameters Found:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model retrained successfully!\n",
      "XGB Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load existing model_df and team_k_stats\n",
    "model_df = pd.read_csv(r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\model_df.csv\")\n",
    "team_k_stats = pd.read_csv(r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\team_k_stats.csv\")\n",
    "\n",
    "# 2. Prepare final features\n",
    "final_features = [\n",
    "    'avg_velocity',\n",
    "    'pct_LHB_faced',\n",
    "    'pitcher_days_since_prev_game',\n",
    "    'pitcher_days_until_next_game',\n",
    "    'ks_last_5_games',\n",
    "    'k_pct_60d',\n",
    "    'is_home_game'  # Added\n",
    "]\n",
    "\n",
    "X = model_df[final_features]\n",
    "y = model_df['total_strikeouts']\n",
    "\n",
    "# 3. Create recency sample weights\n",
    "model_df = model_df.sort_values('game_date').reset_index(drop=True)\n",
    "model_df['recency_rank'] = model_df.index\n",
    "model_df['recency_score'] = model_df['recency_rank'] / model_df['recency_rank'].max()\n",
    "model_df['sample_weight'] = model_df['recency_score'] ** 2\n",
    "\n",
    "sample_weight = model_df['sample_weight']\n",
    "\n",
    "today = date.today()\n",
    "dynamic_seed = int(today.strftime(\"%Y%m%d\"))\n",
    "\n",
    "# 4. Train XGBoost model\n",
    "xgb_final_model = XGBRegressor(\n",
    "    n_estimators=300,       \n",
    "    learning_rate=0.03,     )\n",
    "    max_depth=3,            \n",
    "    subsample=0.7,          \n",
    "    colsample_bytree=1.0,   \n",
    "    random_state=dynamic_seed,\n",
    "    verbosity=1,\n",
    "    min_child_weight = 1,\n",
    "    gamma = 0.2\n",
    ")\n",
    "\n",
    "xgb_final_model.fit(X, y, sample_weight=sample_weight)\n",
    "\n",
    "print(\"Model retrained successfully!\")\n",
    "\n",
    "# 5. Save model\n",
    "joblib.dump(xgb_final_model, r\"C:\\Users\\ianat\\OneDrive\\Documents\\Gambling\\MLB\\Data\\xgb_final_model.pkl\")\n",
    "print(\"XGB Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing any accents in players names to make it easier to lookup\n",
    "def normalize_name(name):\n",
    "    return unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "def predict_strikeouts(pitcher_name, opponent_team, is_home_game=1, alt_lines=None, n_sims=10000, manual_under_odds=None):\n",
    "    # 1. Get the latest record for this pitcher\n",
    "    # Apply normalization to both sides\n",
    "    normalized_pitcher_name = normalize_name(pitcher_name)\n",
    "    model_df['player_name_normalized'] = model_df['player_name'].apply(normalize_name)\n",
    "\n",
    "    # Then match\n",
    "    pitcher_rows = model_df[model_df['player_name_normalized'] == normalized_pitcher_name]\n",
    "    if pitcher_rows.empty:\n",
    "        raise ValueError(f\"No data found for pitcher: {pitcher_name}. Check name spelling or model_df contents.\")\n",
    "\n",
    "    row = pitcher_rows.sort_values('game_date').iloc[-1]\n",
    "\n",
    "    # 2. Get pitcher's throwing hand\n",
    "    p_throws = row.get('p_throws', 'R')  # fallback to RHP if not found\n",
    "\n",
    "    # 3. Lookup opponent K% vs pitcher handedness\n",
    "    if opponent_team not in team_k_stats['batting_team'].values:\n",
    "        print(f\"Warning: Opponent team '{opponent_team}' not found in team_k_stats. Using default 0.22 k_pct.\")\n",
    "        k_pct_60d = 0.22\n",
    "    else:\n",
    "        opponent_k_row = team_k_stats[\n",
    "            (team_k_stats['batting_team'] == opponent_team) & \n",
    "            (team_k_stats['p_throws'] == p_throws)\n",
    "        ]\n",
    "        k_pct_60d = opponent_k_row['k_pct_60d'].values[0] if not opponent_k_row.empty else 0.22\n",
    "\n",
    "    # 4. Safely pull features with fallbacks\n",
    "    input_features = {\n",
    "        'avg_velocity': row['avg_velocity'] if pd.notna(row['avg_velocity']) else 93,\n",
    "        'pct_LHB_faced': row['pct_LHB_faced'] if pd.notna(row['pct_LHB_faced']) else 0.35,\n",
    "        'pitcher_days_since_prev_game': row['pitcher_days_since_prev_game'] if pd.notna(row['pitcher_days_since_prev_game']) else 5,\n",
    "        'pitcher_days_until_next_game': row['pitcher_days_until_next_game'] if pd.notna(row['pitcher_days_until_next_game']) else 5,\n",
    "        'ks_last_5_games': row['ks_last_5_games'] if pd.notna(row['ks_last_5_games']) else 5,\n",
    "        'k_pct_60d': k_pct_60d,\n",
    "        'is_home_game': is_home_game\n",
    "    }\n",
    "\n",
    "    # 5. Predict\n",
    "    input_df = pd.DataFrame([input_features])\n",
    "    prediction = xgb_final_model.predict(input_df)[0]\n",
    "\n",
    "\n",
    "    # 6. Monte Carlo EV simulation (if alt lines provided)\n",
    "    ladder_results = None\n",
    "    under_result = None\n",
    "\n",
    "    if alt_lines:\n",
    "        # Calculate Negative Binomial parameters\n",
    "        today = date.today()\n",
    "        dynamic_seed = int(today.strftime(\"%Y%m%d\"))\n",
    "\n",
    "        rng = np.random.default_rng(seed=dynamic_seed)\n",
    "        sim_ks = rng.poisson(lam=prediction, size=n_sims)\n",
    "\n",
    "        # --- Process Over Ladder Bets ---\n",
    "        results = []\n",
    "        for line, odds in alt_lines:\n",
    "            true_prob = np.mean(sim_ks > line)\n",
    "\n",
    "            # Breakeven calculation\n",
    "            decimal_odds = (odds / 100) + 1 if odds > 0 else (100 / abs(odds)) + 1\n",
    "            breakeven_prob = 1 / decimal_odds\n",
    "\n",
    "            # EV clean method\n",
    "            ev_percentage = (true_prob - breakeven_prob) * 100\n",
    "\n",
    "            results.append({\n",
    "                'Line': line,\n",
    "                'Odds': odds,\n",
    "                'True_Prob': round(true_prob, 4),\n",
    "                'Breakeven_%': round(breakeven_prob * 100, 2),\n",
    "                'EV_%': round(ev_percentage, 2)\n",
    "            })\n",
    "\n",
    "        ladder_results = pd.DataFrame(results)\n",
    "\n",
    "        # ADD BET/PASS column based on dynamic thresholds\n",
    "        rung_thresholds = []\n",
    "        recommendations = []\n",
    "\n",
    "        for i, ev in enumerate(ladder_results['EV_%']):\n",
    "            required_ev = 7 + i  # 7% + 1% per rung\n",
    "            rung_thresholds.append(required_ev)\n",
    "            if ev >= required_ev:\n",
    "                recommendations.append('BET ‚úÖ')\n",
    "            else:\n",
    "                recommendations.append('PASS ‚ùå')\n",
    "\n",
    "        ladder_results['Required_EV_%'] = rung_thresholds\n",
    "        ladder_results['Recommendation'] = recommendations\n",
    "\n",
    "        # --- Process Under Bet on First Rung ---\n",
    "        first_line, first_over_odds = alt_lines[0]\n",
    "\n",
    "        # Manually entered Under odds (if given), otherwise assume mirror\n",
    "        if manual_under_odds is not None:\n",
    "            first_under_odds = manual_under_odds\n",
    "        else:\n",
    "            first_under_odds = -first_over_odds if first_over_odds > 0 else abs(first_over_odds)\n",
    "\n",
    "        true_prob_under = np.mean(sim_ks <= first_line)\n",
    "\n",
    "        decimal_under_odds = (first_under_odds / 100) + 1 if first_under_odds > 0 else (100 / abs(first_under_odds)) + 1\n",
    "        breakeven_prob_under = 1 / decimal_under_odds\n",
    "\n",
    "        ev_percentage_under = (true_prob_under - breakeven_prob_under) * 100\n",
    "\n",
    "        # Threshold for Under EV (can tweak)\n",
    "        under_required_ev = 7.0  # Example: Require +3% EV or better\n",
    "\n",
    "        # Recommendation logic\n",
    "        under_recommendation = 'BET ‚úÖ' if ev_percentage_under >= under_required_ev else 'PASS ‚ùå'\n",
    "\n",
    "        under_result = pd.DataFrame([{\n",
    "            'Line': round(first_line, 1),\n",
    "            'Odds': int(first_under_odds),\n",
    "            'True_Prob': round(true_prob_under * 100, 2),\n",
    "            'Breakeven_%': round(breakeven_prob_under * 100, 2),\n",
    "            'EV_%': round(ev_percentage_under, 2),\n",
    "            'Required_EV_%': under_required_ev,  # Show required threshold\n",
    "            'Recommendation': under_recommendation  # ‚úÖ BET or PASS\n",
    "        }])\n",
    "\n",
    "        \n",
    "\n",
    "    return round(prediction, 2), input_features, ladder_results, under_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 6.3\n",
      "Ladder Results (Over bets):\n",
      "   Line  Odds  True_Prob  Breakeven_%  EV_%  Required_EV_% Recommendation\n",
      "0   5.5  -152     0.5901        60.32 -1.31              7         PASS ‚ùå\n",
      "1   6.5   138     0.4330        42.02  1.28              8         PASS ‚ùå\n",
      "2   7.5   280     0.2941        26.32  3.09              9         PASS ‚ùå\n",
      "3   8.5   560     0.1849        15.15  3.34             10         PASS ‚ùå\n",
      "Under Result:\n",
      "   Line  Odds  True_Prob  Breakeven_%  EV_%  Required_EV_% Recommendation\n",
      "0   5.5   120      40.99        45.45 -4.46            7.0         PASS ‚ùå\n"
     ]
    }
   ],
   
